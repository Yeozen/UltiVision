{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAWfpta5PnnZ"
      },
      "outputs": [],
      "source": [
        "!python -m pip install mediapipe\n",
        "!pip install tensorflow scikit-learn\n",
        "!wget https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/latest/pose_landmarker_lite.task"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#KEYPOINT GENERATION WITHOUT Z COORDINATE\n",
        "\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Define the indices of the desired landmarks (11-16 and 23-32)\n",
        "desired_landmark_indices = list(range(11, 17)) + list(range(23, 33))\n",
        "\n",
        "def process_video(video_path, output_path):\n",
        "    # Initialize MediaPipe Pose for each video\n",
        "    mp_pose = mp.solutions.pose.Pose()\n",
        "\n",
        "    # Open video capture\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # List to store selected landmarks\n",
        "    selected_landmarks = []\n",
        "\n",
        "    while True:\n",
        "        # Read a frame\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Convert the frame to RGB\n",
        "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Process the frame with MediaPipe Pose\n",
        "        results = mp_pose.process(rgb_frame)\n",
        "\n",
        "        # Extract and store selected landmarks if available\n",
        "        if results.pose_landmarks:\n",
        "            # Create a new list for each frame to store the landmarks\n",
        "            landmarks_frame = []\n",
        "\n",
        "            for idx in desired_landmark_indices:\n",
        "                landmark = results.pose_landmarks.landmark[idx]\n",
        "\n",
        "                landmarks_frame.append({\n",
        "                    \"index\": idx,\n",
        "                    \"name\": mp.solutions.pose.PoseLandmark(idx).name,\n",
        "                    \"x\": landmark.x,\n",
        "                    \"y\": landmark.y\n",
        "                })\n",
        "\n",
        "            # Append the landmarks of the current frame to the main list\n",
        "            selected_landmarks.append(landmarks_frame)\n",
        "\n",
        "    # Release the video capture\n",
        "    cap.release()\n",
        "\n",
        "    # Save selected landmarks in JSON format\n",
        "    json_data = json.dumps(selected_landmarks, indent=2)\n",
        "    with open(output_path, 'w') as json_file:\n",
        "        json_file.write(json_data)\n",
        "\n",
        "    # Close the MediaPipe Pose instance\n",
        "    mp_pose.close()\n",
        "\n",
        "# Specify the directory containing your videos\n",
        "videos_directory = '/content/drive/MyDrive/RAW FRISBEE FOOTAGE/NO_PIVOT'\n",
        "\n",
        "# Specify the directory to save the output JSON files\n",
        "output_directory = '/content/drive/MyDrive/RAW FRISBEE FOOTAGE/NO_PIVOT_JSON'\n",
        "\n",
        "# Loop through each video file in the specified directory\n",
        "for video_file in os.listdir(videos_directory):\n",
        "    if video_file.endswith('.mp4'):  # Adjust the file extension as needed\n",
        "        video_path = os.path.join(videos_directory, video_file)\n",
        "        output_path = os.path.join(output_directory, f'{video_file[:-4]}_keypoints.json')  # Create a unique output file for each video\n",
        "        process_video(video_path, output_path)\n",
        "\n",
        "print(\"Processing completed.\")\n"
      ],
      "metadata": {
        "id": "eK18jQ_Y32xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#USE THIS FOR KEYPOINT GENERATION IF WANT INCLUDE Z COORDINATE\n",
        "\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Define the indices of the desired landmarks (11-16 and 23-32)\n",
        "desired_landmark_indices = list(range(11, 17)) + list(range(23, 33))\n",
        "\n",
        "def process_video(video_path, output_path, label):\n",
        "    # Initialize MediaPipe Pose for each video\n",
        "    mp_pose = mp.solutions.pose.Pose()\n",
        "\n",
        "    # Open video capture\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # List to store selected landmarks\n",
        "    selected_landmarks = []\n",
        "\n",
        "    while True:\n",
        "        # Read a frame\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Convert the frame to RGB\n",
        "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Process the frame with MediaPipe Pose\n",
        "        results = mp_pose.process(rgb_frame)\n",
        "\n",
        "        # Extract and store selected landmarks if available\n",
        "        if results.pose_landmarks:\n",
        "            # Create a new list for each frame to store the landmarks\n",
        "            landmarks_frame = []\n",
        "\n",
        "            for idx in desired_landmark_indices:\n",
        "                landmark = results.pose_landmarks.landmark[idx]\n",
        "\n",
        "                landmarks_frame.append({\n",
        "                    \"index\": idx,\n",
        "                    \"name\": mp.solutions.pose.PoseLandmark(idx).name,\n",
        "                    \"x\": landmark.x,\n",
        "                    \"y\": landmark.y,\n",
        "                    \"z\": landmark.z\n",
        "                })\n",
        "\n",
        "            # Append the landmarks of the current frame to the main list\n",
        "            selected_landmarks.append(landmarks_frame)\n",
        "\n",
        "    # Release the video capture\n",
        "    cap.release()\n",
        "\n",
        "    # Save selected landmarks in JSON format\n",
        "    json_data = json.dumps(selected_landmarks, indent=2)\n",
        "    with open(output_path, 'w') as json_file:\n",
        "        json_file.write(json_data)\n",
        "\n",
        "    # Close the MediaPipe Pose instance\n",
        "    mp_pose.close()\n",
        "\n",
        "def label_videos_by_folder(videos_directory):\n",
        "    labels = []\n",
        "    videos = []\n",
        "    for label_folder in os.listdir(videos_directory):\n",
        "        label_path = os.path.join(videos_directory, label_folder)\n",
        "        if os.path.isdir(label_path):\n",
        "            for video_file in os.listdir(label_path):\n",
        "                if video_file.endswith('.mp4'):\n",
        "                    video_path = os.path.join(label_path, video_file)\n",
        "                    labels.append(label_folder)\n",
        "                    videos.append(video_path)\n",
        "    return videos, labels\n",
        "\n",
        "# Specify the directory containing your videos\n",
        "videos_directory = '/content/onedrive/FYP/AUGMENTED'\n",
        "\n",
        "# Specify the directory to save the output JSON files\n",
        "output_directory = '/content/onedrive/FYP/JSON'\n",
        "\n",
        "# Label videos based on the folder they are in\n",
        "video_paths, labels = label_videos_by_folder(videos_directory)\n",
        "\n",
        "#USE THIS FOR UNAUGMENTED\n",
        "# Loop through each video file in the specified directory\n",
        "#for video_path, label in zip(video_paths, labels):\n",
        "    # Get the video name without the extension\n",
        "    #video_name = os.path.basename(video_path)[:-4]\n",
        "    # Include the folder name (label) as part of the output file name\n",
        "    #output_path = os.path.join(output_directory, f'{label}_{video_name}_keypoints.json')\n",
        "\n",
        "#USE THIS FOR AUGMENTED FOLDER\n",
        "# Loop through each video file in the specified directory\n",
        "for video_path, label in zip(video_paths, labels):\n",
        "    # Split the original video name into label and name\n",
        "    original_label, video_name = os.path.basename(video_path)[:-4].split('_', 1)\n",
        "    # Include the folder name (label) in between the original label and the video name\n",
        "    output_path = os.path.join(output_directory, f'{original_label}_{label}_{video_name}_keypoints.json')\n",
        "    process_video(video_path, output_path, label)\n",
        "\n",
        "    # Check if the file already exists\n",
        "    if os.path.exists(output_path):\n",
        "        print(f\"Skipping {output_path} as it already exists.\")\n",
        "        continue\n",
        "\n",
        "    process_video(video_path, output_path, label)\n",
        "\n",
        "print(\"Processing completed.\")\n"
      ],
      "metadata": {
        "id": "NQBCQYZw35gM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4hgTHmHA7Jn",
        "outputId": "8e4db962-9fc8-4efd-b379-dafef48c3d8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['BOTH' 'GOOD' 'NO FLICK' 'PIVOT']\n"
          ]
        }
      ],
      "source": [
        "#pre-processing 3 coordinate keypoint data\n",
        "\n",
        "import numpy as np\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "import os\n",
        "import joblib\n",
        "\n",
        "# Initialize lists to hold data and labels\n",
        "X_data = []\n",
        "y_data = []\n",
        "\n",
        "# Specify the directory where the JSON files are located\n",
        "directory = '/content/onedrive/FYP/JSON'\n",
        "\n",
        "# Read each JSON file in the directory\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith('.json'):\n",
        "        with open(os.path.join(directory, filename), 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        # Convert the data to a list of frames, each frame being a list of [x, y, z] coordinates\n",
        "        sequence_data = [[[entry['x'], entry['y'], entry['z']] for entry in frame] for frame in data]\n",
        "        X_data.append(sequence_data)\n",
        "\n",
        "\n",
        "        # Extract the label from the filename and append it to y_data\n",
        "        label = filename.split('_')[0]\n",
        "        y_data.append(label)\n",
        "\n",
        "# Define max_sequence_length as the length of the longest sequence in X_data\n",
        "max_sequence_length = max(len(sequence) for sequence in X_data)\n",
        "\n",
        "# Convert data to numpy arrays\n",
        "X_data = pad_sequences(X_data, maxlen=max_sequence_length, padding='post', dtype='float32')\n",
        "y_data = np.array(y_data)\n",
        "\n",
        "# Initialize an encoder to convert labels to numerical format\n",
        "label_encoder = LabelEncoder()\n",
        "y_data_encoded = label_encoder.fit_transform(y_data)\n",
        "\n",
        "print(label_encoder.classes_)\n",
        "# Save the fitted LabelEncoder\n",
        "joblib.dump(label_encoder, '/content/onedrive/FYP/label_encoder.joblib')\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Save the data\n",
        "np.save('/content/onedrive/FYP/TRAINING/X_train_with_z.npy', X_train)\n",
        "np.save('/content/onedrive/FYP/TRAINING/X_test_with_z.npy', X_test)\n",
        "np.save('/content/onedrive/FYP/TRAINING/y_train_test_with_z.npy', y_train)\n",
        "np.save('/content/onedrive/FYP/TRAINING/y_test_test_with_z.npy', y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pre-processing 2 coordinate keypoint data\n",
        "\n",
        "import numpy as np\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "import os\n",
        "import joblib\n",
        "\n",
        "# Initialize lists to hold data and labels\n",
        "X_data = []\n",
        "y_data = []\n",
        "\n",
        "# Specify the directory where the JSON files are located\n",
        "directory = '/content/onedrive/FYP/JSON_NO_Z'\n",
        "\n",
        "# Read each JSON file in the directory\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith('.json'):\n",
        "        with open(os.path.join(directory, filename), 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        # Convert the data to a list of frames, each frame being a list of [x, y] coordinates\n",
        "        sequence_data = [[[entry['x'], entry['y']] for entry in frame] for frame in data]\n",
        "        X_data.append(sequence_data)\n",
        "\n",
        "        # Extract the label from the filename and append it to y_data\n",
        "        label = filename.split('_')[0]\n",
        "        y_data.append(label)\n",
        "\n",
        "# Define max_sequence_length as the length of the longest sequence in X_data\n",
        "max_sequence_length = max(len(sequence) for sequence in X_data)\n",
        "\n",
        "# Convert data to numpy arrays\n",
        "X_data = pad_sequences(X_data, maxlen=max_sequence_length, padding='post', dtype='float32')\n",
        "y_data = np.array(y_data)\n",
        "\n",
        "# Initialize an encoder to convert labels to numerical format\n",
        "label_encoder = LabelEncoder()\n",
        "y_data_encoded = label_encoder.fit_transform(y_data)\n",
        "\n",
        "print(label_encoder.classes_)\n",
        "# Save the fitted LabelEncoder\n",
        "joblib.dump(label_encoder, '/content/onedrive/FYP/label_encoder_no_z.joblib')\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Save the data\n",
        "np.save('/content/onedrive/FYP/TRAINING/X_train_no_z.npy', X_train)\n",
        "np.save('/content/onedrive/FYP/TRAINING/X_test_no_z.npy', X_test)\n",
        "np.save('/content/onedrive/FYP/TRAINING/y_train_no_z.npy', y_train)\n",
        "np.save('/content/onedrive/FYP/TRAINING/y_test_no_z.npy', y_test)"
      ],
      "metadata": {
        "id": "1x8_B2Wp2ly4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OoUnE01ULjNS"
      },
      "outputs": [],
      "source": [
        "#training LSTM model with z coordinate\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, TimeDistributed, Flatten\n",
        "\n",
        "# Load the data\n",
        "X_train = np.load('/content/onedrive/FYP/TRAINING/X_train_with_z.npy')\n",
        "X_test = np.load('/content/onedrive/FYP/TRAINING/X_test_with_z.npy')\n",
        "y_train = np.load('/content/onedrive/FYP/TRAINING/y_train_with_z.npy')\n",
        "y_test = np.load('/content/onedrive/FYP/TRAINING/y_test_with_z.npy')\n",
        "\n",
        "# Create a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add a TimeDistributed wrapper to apply the LSTM layer to each sequence\n",
        "model.add(TimeDistributed(LSTM(64, return_sequences=True), input_shape=(60, 16, 3)))\n",
        "model.add(TimeDistributed(LSTM(64)))\n",
        "\n",
        "# Flatten the output of the LSTM layers\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add a Dense layer\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "# Add a dense layer with 4 units (for the 4 classes) and a softmax activation function\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=32, validation_data=(X_test, y_test), shuffle=True)\n",
        "#EPOCH 32\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print('Loss:', loss)\n",
        "print('Accuracy:', accuracy)\n",
        "\n",
        "# Save the model\n",
        "model.save('/content/onedrive/FYP/MODEL/frisbee.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqaSIvEeKdnP"
      },
      "outputs": [],
      "source": [
        "#training transformer model\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.layers import Layer, MultiHeadAttention, Flatten, TimeDistributed\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the data\n",
        "X_train = np.load('/content/onedrive/FYP/TRAINING/X_train_with_z.npy')\n",
        "X_test = np.load('/content/onedrive/FYP/TRAINING/X_test_with_z.npy')\n",
        "y_train = np.load('/content/onedrive/FYP/TRAINING/y_train_with_z.npy')\n",
        "y_test = np.load('/content/onedrive/FYP/TRAINING/y_test_with_z.npy')\n",
        "\n",
        "# Custom Transformer layer\n",
        "class TransformerBlock(Layer):\n",
        "    def __init__(self, num_heads, key_dim, **kwargs):\n",
        "        super(TransformerBlock, self).__init__(**kwargs)\n",
        "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.att(query=inputs, key=inputs, value=inputs)\n",
        "        return x\n",
        "\n",
        "# Create a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add the custom Transformer layer\n",
        "model.add(TimeDistributed(TransformerBlock(num_heads=8, key_dim=8), input_shape=(60, 16, 3)))\n",
        "\n",
        "# Add a Flatten layer to reduce the dimensionality\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add a Dense layer\n",
        "model.add(Dense(128, activation='relu', kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02)))\n",
        "\n",
        "# Add a dense layer with 4 units (for the 4 classes) and a softmax activation function\n",
        "model.add(Dense(4, activation='softmax', kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02)))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=33, validation_data=(X_test, y_test), shuffle=True)\n",
        "#epoch 31\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print('Loss:', loss)\n",
        "print('Accuracy:', accuracy)\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save the model\n",
        "model.save('/content/onedrive/FYP/MODEL/transformer_frisbee.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAG8HDv0c8fc"
      },
      "outputs": [],
      "source": [
        "#training LSTM model without z coordinate\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Flatten, TimeDistributed\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the data\n",
        "X_train = np.load('/content/onedrive/FYP/TRAINING/X_train_no_z.npy')\n",
        "X_test = np.load('/content/onedrive/FYP/TRAINING/X_test_no_z.npy')\n",
        "y_train = np.load('/content/onedrive/FYP/TRAINING/y_train_no_z.npy')\n",
        "y_test = np.load('/content/onedrive/FYP/TRAINING/y_test_no_z.npy')\n",
        "\n",
        "# Create a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add a TimeDistributed wrapper to apply the LSTM layer to each sequence\n",
        "model.add(TimeDistributed(LSTM(64, return_sequences=True), input_shape=(60, 16, 2)))\n",
        "model.add(TimeDistributed(LSTM(64)))\n",
        "\n",
        "# Flatten the output of the LSTM layers\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add a Dense layer\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "# Add a dense layer with 5 units (for the 5 classes) and a softmax activation function\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print('Loss:', loss)\n",
        "print('Accuracy:', accuracy)\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save the model\n",
        "model.save('/content/onedrive/FYP/frisbee_no_z.keras')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}